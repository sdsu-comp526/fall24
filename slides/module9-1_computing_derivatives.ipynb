{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4159be0e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 36) Computing Derivatives\n",
    "\n",
    "## Last time\n",
    "\n",
    "* Linear Models\n",
    "* Optimization\n",
    "* Partial Derivatives\n",
    "\n",
    "## Today\n",
    "1. Computing derivatives  \n",
    "  1.1 Numeric  \n",
    "  1.2 Analytic by hand  \n",
    "  1.3 Algorithmic (automatic) differentiation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627277ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Computing derivatives "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f69462",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We know the definition of the difference quotient from Calculus:\n",
    "\n",
    "$$\\lim_{h\\to 0} \\frac{f(x+h) - f(x)}{h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1b145",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* How should we choose $h$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d0812",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Taylor series\n",
    "\n",
    "Classical accuracy analysis assumes that functions are sufficiently smooth, meaning that derivatives exist and Taylor expansions are valid within a neighborhood.  In particular,\n",
    "$$ f(x+h) = f(x) + f'(x) h + f''(x) \\frac{h^2}{2!} + \\underbrace{f'''(x) \\frac{h^3}{3!} + \\dotsb}_{O(h^3)} . $$\n",
    "\n",
    "The big-$O$ notation is meant in the limit $h\\to 0$.  Specifically, a function $g(h) \\in O(h^p)$ (sometimes written $g(h) = O(h^p)$) when\n",
    "there exists a constant $C$ such that\n",
    "$$ g(h) \\le C h^p $$\n",
    "for all sufficiently *small* $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c564912",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rounding error\n",
    "\n",
    "We have an additional source of error, *rounding error*, which comes from not being able to compute $f(x)$ or $f(x+h)$ exactly, nor subtract them exactly.  Suppose that we can, however, compute these functions with a relative error on the order of $\\epsilon_{\\text{machine}}$.  This leads to\n",
    "$$ \\begin{split}\n",
    "\\tilde f(x) &= f(x)(1 + \\epsilon_1) \\\\\n",
    "\\tilde f(x \\oplus h) &= \\tilde f((x+h)(1 + \\epsilon_2)) \\\\\n",
    "&= f((x + h)(1 + \\epsilon_2))(1 + \\epsilon_3) \\\\\n",
    "&= [f(x+h) + f'(x+h)(x+h)\\epsilon_2 + O(\\epsilon_2^2)](1 + \\epsilon_3) \\\\\n",
    "&= f(x+h)(1 + \\epsilon_3) + f'(x+h)x\\epsilon_2 + O(\\epsilon_{\\text{machine}}^2 + \\epsilon_{\\text{machine}} h)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b39cf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tedious error propagation\n",
    "$$ \\begin{split}\n",
    "\\left\\lvert \\frac{\\tilde f(x+h) \\ominus \\tilde f(x)}{h} - \\frac{f(x+h) - f(x)}{h} \\right\\rvert &=\n",
    "  \\left\\lvert \\frac{f(x+h)(1 + \\epsilon_3) + f'(x+h)x\\epsilon_2 + O(\\epsilon_{\\text{machine}}^2 + \\epsilon_{\\text{machine}} h) - f(x)(1 + \\epsilon_1) - f(x+h) + f(x)}{h} \\right\\rvert \\\\\n",
    "  &\\le \\frac{|f(x+h)\\epsilon_3| + |f'(x+h)x\\epsilon_2| + |f(x)\\epsilon_1| + O(\\epsilon_{\\text{machine}}^2 + \\epsilon_{\\text{machine}}h)}{h} \\\\\n",
    "  &\\le \\frac{(2 \\max_{[x,x+h]} |f| + \\max_{[x,x+h]} |f' x| \\epsilon_{\\text{machine}} + O(\\epsilon_{\\text{machine}}^2 + \\epsilon_{\\text{machine}} h)}{h} \\\\\n",
    "  &= (2\\max|f| + \\max|f'x|) \\frac{\\epsilon_{\\text{machine}}}{h} + O(\\epsilon_{\\text{machine}}) \\\\\n",
    "\\end{split} $$\n",
    "where we have assumed that $h \\ge \\epsilon_{\\text{machine}}$.\n",
    "This error becomes large (relative to $f'$ -- we are concerned with relative error after all).\n",
    "\n",
    "What can be problematic:\n",
    "\n",
    "* $f$ is large compared to $f'$\n",
    "* $x$ is large\n",
    "* $h$ is too small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d442032",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Automatic step size selection \n",
    "\n",
    "Reference [Numerical Optimization](https://www.math.uci.edu/~qnie/Publications/NumericalOptimization.pdf)\n",
    "\n",
    "* Walker and Pernice\n",
    "* Dennis and Schnabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508cef2",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "diff(f, x; h=1e-8) = (f(x+h) - f(x)) / h\n",
    "\n",
    "function diff_wp(f, x; h=1e-8)\n",
    "    \"\"\"Diff using Walker and Pernice (1998) choice of step\"\"\"\n",
    "    h *= (1 + abs(x))\n",
    "    (f(x+h) - f(x)) / h\n",
    "end\n",
    "\n",
    "x = 1000\n",
    "diff_wp(sin, x) - cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13598631",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.1 Symbolic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa185815",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Symbolics\")\n",
    "\n",
    "using Symbolics\n",
    "\n",
    "@variables x\n",
    "Dx = Differential(x)\n",
    "\n",
    "y = sin(x)\n",
    "Dx(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e4153",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "expand_derivatives(Dx(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8ae35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Awesome, what about products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4243eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x\n",
    "for _ in 1:2\n",
    "    y = cos(y^pi) * log(y)\n",
    "end\n",
    "expand_derivatives(Dx(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b799be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The size of these expressions can grow **exponentially**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a680f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Hand-coding (analytic) derivatives\n",
    "\n",
    "$$ df = f'(x) dx $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fb506",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "function f(x)\n",
    "    y = x\n",
    "    for _ in 1:2\n",
    "        a = y^pi\n",
    "        b = cos(a)\n",
    "        c = log(y)\n",
    "        y = b * c\n",
    "    end\n",
    "    y\n",
    "end\n",
    "\n",
    "f(1.9), diff_wp(f, 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dec50b",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function df(x, dx)\n",
    "    y = x\n",
    "    dy = dx\n",
    "    for _ in 1:2\n",
    "        a = y ^ pi\n",
    "        da = pi * y^(pi - 1) * dy\n",
    "        b = cos(a)\n",
    "        db = -sin(a) * da\n",
    "        c = log(y)\n",
    "        dc = dy / y\n",
    "        y = b * c\n",
    "        dy = db * c + b * dc\n",
    "    end\n",
    "    y, dy\n",
    "end\n",
    "\n",
    "df(1.9, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb72ae9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We can go the other way\n",
    "\n",
    "We can differentiate a composition $h(g(f(x)))$ as\n",
    "\n",
    "\\begin{align}\n",
    "  \\operatorname{d} h &= h' \\operatorname{d} g \\\\\n",
    "  \\operatorname{d} g &= g' \\operatorname{d} f \\\\\n",
    "  \\operatorname{d} f &= f' \\operatorname{d} x.\n",
    "\\end{align}\n",
    "\n",
    "What we've done above is called \"forward mode\", and amounts to placing the parentheses in the chain rule like\n",
    "\n",
    "$$ \\operatorname d h = \\frac{dh}{dg} \\left(\\frac{dg}{df} \\left(\\frac{df}{dx} \\operatorname d x \\right) \\right) .$$\n",
    "\n",
    "The expression means the same thing if we rearrange the parentheses,\n",
    "\n",
    "$$ \\operatorname d h = \\left( \\left( \\left( \\frac{dh}{dg} \\right) \\frac{dg}{df} \\right) \\frac{df}{dx} \\right) \\operatorname d x .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e01ae1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3 Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052e15a",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Zygote\")\n",
    "\n",
    "import Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabcb46",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "Zygote.gradient(f, 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g(x) = exp(x) + x^2\n",
    "@code_llvm Zygote.gradient(g, 1.9)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
